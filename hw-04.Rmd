---
title: 'Poisson Regression'
author: "STA 310: Homework 4, Luke Flyer"
output: pdf_document
---

Instructions:

-   Write all narrative using full sentences. Write all interpretations and conclusions in the context of the data.

-   Be sure all analysis code is displayed in the rendered pdf.

-   If you are fitting a model, display the model output in a neatly formatted table. (The tidy and kable functions can help!)

-   If you are creating a plot, use clear and informative labels and titles.

-   Make sure to upload to both Gradescope and Canvas in a reproducible format per the instructions of prior homework assignments.

These exercises are derived from BMLR, Chapter 4.

<!--BMLR Sec 4.11.1 Ex 11-->

1.  

Answer parts a - d in the context of the following study:

A state wildlife biologist collected data from 250 park visitors as they left at the end of their stay. Each was asked to report the number of fish they caught during their one-week stay. On average, visitors caught 21.5 fish per week.

a.  Define the response.

    The response is the number of fish each visitor caught during their one-week stay.

b.  What are the possible values for the response?

    The possible values for the response are non-negative integers (0, 1, 2, 3, and so on).

c.  What does $\lambda$ represent?

    $\lambda$ represents the rate parameter for the Poisson distribution, so in this case, it would be the expected number of fish caught by a visitor during their one-week stay. It is 21.5 fish as given.

d.  Would a zero-inflated model be considered here? If so, what would be a "true zero"?

    It is definitely reasonable for a zero-inflated model to be considered here. It is conceivable that many of the 250 visitors in the sample did not even go fishing, or they were expecting to, but weren't able to actually go fishing. Of course, we would need to view the actual data to see if there was an overabundance of zeros. The "true zeros" here (those that are going to be excluded from the Poisson process) would be those visitors who did not even attempt fishing (or didn't go fishing for some other reason). Conceivably, there could also be the presence of the other type of zero, which is just a visitor who went fishing but didn't happen to catch anything, and the ZIP model would treat these accordingly.

<!-- -->

2.  <!--From Sec. 4.11.2, Ex. 2-->

@brockmann1996 carried out a study of nesting female horseshoe crabs. Female horseshoe crabs often have male crabs attached to a female's nest known as satellites. One objective of the study was to determine which characteristics of the female were associated with the number of satellites. Of particular interest is the relationship between the width of the female carapace and satellites.

The data can be found in crab.csv in the data folder. It includes the following variables:

-   Satellite = number of satellites

-   Width = carapace width (cm)

-   Weight = weight (kg)

-   Spine = spine condition (1 = both good, 2 = one worn or broken, 3 = both worn or broken)

-   Color = color (1 = light medium, 2 = medium, 3 = dark medium, 4 = dark)

Make sure to convert Spine and Color to the appropriate data types in R before doing the analysis.

a.  Create a histogram of Satellite. Is there preliminary evidence the number of satellites could be modeled as a Poisson response? Briefly explain.

    ```{r}

    library(knitr)
    library(magrittr)
    library(kableExtra)
    library(tidyverse)
    library(tidymodels)

    crabs <- read.csv("crab.csv")

    ggplot(crabs, aes(x = Satellite)) +
      geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
      labs(
        title = "Histogram of Satellite Counts", 
        x = "Number of Satellites", 
        y = "Frequency") +
      theme_minimal()
    ```

    From this histogram, it seems like there is an overabundance of zeros. Therefore, it is more likely that a zero-inflated model would be useful rather than a regular Poisson response. The data is right skewed, which follows the general pattern of a Poisson distribution, but the large amount of zeros is definitely evidence against a strictly Poisson model.

b.  Fit a Poisson regression model including Width, Weight, and Spine as predictors. Display the model with the 95% confidence interval for each coefficient.

    ```{r}

    crabs$Spine <- as.factor(crabs$Spine)
    crabs$Color <- as.factor(crabs$Color)

    poisson_crabs <- glm(Satellite ~ Width + Weight + Spine, family = "poisson", data = crabs)

    tidy(poisson_crabs, conf.int = TRUE) |>
      kable(digits = 4)
    ```

    ```{r}

    exp(-0.2144)
    exp(-0.0493)
    ```

c.  Describe the effect of Spine in terms of the mean number of satellites.

    The mean number of satellites for females with one worn or broken spine is approximately 0.81 times as large as the number of satellites for females with both good spines when controlling for weight and carapace width.

    The mean number of satellites for females with both worn or broken spines is approximately 0.95 times as large as the number of satellites for females with both good spines when controlling for weight and carapace width.

<!-- -->

3.  Use the scenario from the previous exercise to answer questions (a) - (d).

<!-- -->

a.  We would like to fit a quasi-Poisson regression model for this data. Briefly explain why we may want to consider fitting a quasi-Poisson regression model for this data.

    ```{r}
    mean(crabs$Satellite)
    var(crabs$Satellite)
    ```

    We want to use a quasi-Poisson regression model for this data because the data has the problem of overdispersion, which means that the variance of satellite count is larger than the mean satellite count. A Poisson model assumes that the mean and variance are equal, so using a quasi-Poisson model is more appropriate here to account for overdispersion using a dispersion parameter.

b.  Fit a quasi-Poisson regression model that corresponds with the model chosen in the previous exercise. Display the model.

    ```{r}

    quasi_poisson_crabs <- glm(Satellite ~ Width + Weight + Spine, family = quasipoisson, data = crabs)

    tidy(quasi_poisson_crabs, conf.int = TRUE) |>
      kable(digits = 4)
    ```

c.  What is the estimated dispersion parameter? Show how this value is calculated.

    The estimated dispersion parameter is calculated by dividing the sum of the squared Pearson residuals by the degrees of freedom for the residuals (n - p, where p is the total number of terms in the model). It can be written as follows:

    $$
    \hat{\phi} = \frac{\sum_{i=1}^{n} (\text{Pearson residuals})^2}{n - p}
    $$

    ```{r}

    dispersion <- 
      sum(resid(quasi_poisson_crabs, type = "pearson")^2) / quasi_poisson_crabs$df.residual
    dispersion

    ```

    For this model, our estimated dispersion parameter is approximately 3.169.

d.  How do the estimated coefficients change compared to the model chosen in the previous exercise? How do the standard errors change?

    The estimated coefficients are almost exactly the same as the model chosen in the previous exercise. The standard errors are a little bit larger in this new quasi-Poisson model compared with the Poisson. This is because this new model accounts for overdispersion, and the standard errors become larger because of the addition of the dispersion parameter.

<!-- -->

4.  The goal of this exercise is to use simulation to understand the equivalency between a gamma-Poisson mixture and a negative binomial distribution.

Remember to set a seed so your simulations are reproducible!

<!--BMLR Sec 3.7.2, Ex 2-->

a.  Use the R function rpois() to generate 10,000 $x_i$ from a regular Poisson distribution, $X \sim \textrm{Poisson}(\lambda=1.5)$. Plot a histogram of this distribution and note its mean and variance. Next, let $Y \sim \textrm{Gamma}(r = 3, \lambda = 2)$ and use rgamma() to generate 10,000 random $y_i$ from this distribution.

    ```{r}

    set.seed(7)

    lambda <- 1.5
    n <- 10000
    poisson_data <- rpois(n, lambda)

    poisson_df <- data.frame(poisson_data)

    r <- 3
    lambda_gamma <- 2
    gamma_data <- rgamma(n, shape = r, rate = lambda_gamma)

    ggplot(poisson_df, aes(x = poisson_data)) +
      geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
      labs(title = "Histogram of Poisson Distribution (lambda = 1.5)", 
           x = "Value", y = "Frequency") +
      theme_minimal() +
      scale_x_continuous(breaks = seq(0, max(poisson_data), by = 1))
    ```

    ```{r}

    mean(poisson_data)
    var(poisson_data)
    ```

    Now, consider 10,000 different Poisson distributions where $\lambda_i = y_i$. Randomly generate one $z_i$ from each Poisson distribution. Plot a histogram of these $z_i$ and compare it to your original histogram of $X$ (where $X \sim \textrm{Poisson}(1.5)$). How do the means and variances compare?

    ```{r}

    set.seed(7)

    poisson_from_gamma <- rpois(n, lambda = gamma_data)

    df_gamma_poisson <- data.frame(poisson_from_gamma)

    ggplot(df_gamma_poisson, aes(x = poisson_from_gamma)) +
      geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
      labs(title = "Histogram of Gamma-Poisson Mixture Distribution", 
           x = "Value", y = "Frequency") +
      theme_minimal() +
      scale_x_continuous(breaks = seq(0, max(poisson_from_gamma), by = 5))
    ```

    ```{r}

    mean(poisson_from_gamma)
    var(poisson_from_gamma)
    ```

    When comparing the two histograms, we can clearly see that the most common value from the Poisson distribution is 1, where for the gamma-Poisson, it is 0. The other major difference is the length of the right tail. Both distributions are right-skewed, but the gamma-Poisson has a larger right tail, extending all the way to about 11, where the Poisson only extends to 8. We can see these differences clearly through descriptive statistics with the gamma-Poisson having a larger mean and variance (mean = 1.5, variance = 2.3) than the Poisson (mean = 1.5, variance = 1.5). It should also be noted that the mean and variance are (approximately) equal for the Poisson but not for the gamma-Poisson.

b.  A negative binomial distribution can actually be expressed as a gamma-Poisson mixture. In Part a, you looked at a gamma-Poisson mixture $Z \sim \textrm{Poisson}(\lambda)$ where $\lambda \sim \textrm{Gamma}(r = 3, \lambda' = 2)$.

    Find the parameters of a negative binomial distribution $X \sim \textrm{NegBinom}(r, p)$ such that $X$ is equivalent to $Z$. As a hint, the means of both distributions must be the same, so $\frac{r(1-p)}{p} = \frac{3}{2}$.

    Set the means equal and solve for r(1-p):

    $$
    \frac{r(1 - p)}{p} = \frac{3}{2}
    $$

    Plugging in r = 3 into the above equation, we get p = 2/3.

    Now, we have both of our parameters for the negative binomial distribution. Therefore, we have a distribution as follows: $X \sim \textrm{NegBinom}(3, \frac{2}{3})$

    Show through histograms and summary statistics that your negative binomial distribution is equivalent to the gamma-Poisson mixture. You can use rnbinom() in R.

    ```{r}

    set.seed(26)

    r_nb <- 3     
    p_nb <- 2/3      

    nb <- rnbinom(10000, size = r_nb, prob = p_nb)

    df_nb <- data.frame(nb)

    ggplot(df_nb, aes(x = nb)) +
      geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
      labs(title = "Histogram of Negative Binomial Distribution", 
           x = "Value", y = "Frequency") +
      theme_minimal() +
      scale_x_continuous(breaks = seq(0, max(poisson_from_gamma), by = 5))
    ```

    ```{r}

    mean(nb)
    var(nb)
    ```

    We can see that the histogram for this negative binomial distribution has approximately the same shape and median as the gamma-Poisson mixture. Also, the mean and variance are approximately equal for both distributions.

c.  Make an argument that if you want a $\textrm{NegBinom}(r, p)$ random variable, you can instead sample from a Poisson distribution, where the $\lambda$ values are themselves sampled from a gamma distribution with parameters $r$ and $\lambda' = \frac{p}{1-p}$. You may show equivalency via the simulations or mathematically, however, make sure your arguments are precise and clear.

    We have just conducted two simulations that outputted approximately equivalent results. In the first simulation, the gamma-Poisson distribution, we drew 10,000 times from this distribution modeled by $Z \sim \textrm{Poisson}(\lambda)$where $\lambda \sim \textrm{Gamma}(r = 3, \lambda' = 2)$. In the second simulation, we drew 10,000 times from a a distribution modeled by $\textrm{NegBinom}(3, \frac{2}{3})$. As we can see, the $\lambda'$ value (= 2) used in the gamma-Poisson distribution is equal to $\frac{p}{1-p}$ where $p = \frac{2}{3}$. The r parameter in both distribution is equal—in this case, we have r = 3. We could see when comparing the histograms that the shape of the distributions are equal. The visualization below shows the two histograms overlapped to illustrate the equivalency.

    ```{r}

    df_combined <- data.frame(
      value = c(df_nb$nb, df_gamma_poisson$poisson_from_gamma),
      distribution = rep(c("Negative Binomial", "Gamma-Poisson mixture"), 
                         times = c(nrow(df_nb), nrow(df_gamma_poisson)))
    )

    ggplot(df_combined, aes(x = value, fill = distribution)) +
      geom_histogram(binwidth = 1, color = "black", alpha = 0.7, position = "identity") +
      labs(title = "Overlay of Negative Binomial and Gamma-Poisson Mixture",
           x = "Value", y = "Frequency") +
      theme_minimal() +
      scale_x_continuous(breaks = seq(0, max(df_combined$value), by = 5)) +
      scale_fill_manual(values = c("lightblue", "lightgreen")) +
      theme(legend.title = element_blank())
    ```

    From the descriptive statistics gathered in the previous section, we also found that the means and variances of the two distributions were approximately equal. Through visualization and simulation, we have shown empirically that if you want a $\textrm{NegBinom}(r, p)$ random variable, you can instead sample from a Poisson distribution, where the $\lambda$ values are themselves sampled from a gamma distribution with parameters $r$ and $\lambda' = \frac{1-p}{p}$.

<!-- -->

5.  In a 2018 study, Chapp et al. (2018) scraped every issue statement from webpages of candidates for the U.S. House of Representatives, counting the number of issues candidates commented on and scoring the level of ambiguity of each statement. We will focus on the issue counts, and determining which attributes (of both the district as a whole and the candidates themselves) are associated with candidate silence (commenting on 0 issues) and a willingness to comment on a greater number of issues. The data set is in ambiguity.csv in the data folder . This analysis will focus on the following variables:

-   name : candidate name

-   distID : unique identification number for Congressional district

-   ideology : candidate left-right orientation

-   democrat : 1 if Democrat, 0 if Republican

-   totalIssuePages : number of issues candidates commented on (response)

See @roback2021beyond for the full list of variables.

We will use a hurdle model to analyze the data. A hurdle model is similar to a zero-inflated Poisson model, but instead of assuming that "zeros" are comprised of two distinct groups—those who would always be 0 and those who happen to be 0 on this occasion—the hurdle model assumes that "zeros" are a single entity. Therefore, in a hurdle model, cases are classified as either "zeros" or "non-zeros", where "non-zeros" hurdle the 0 threshold—they must always have counts of 1 or above.

We will use the pscl package and the hurdle function in it to analyze a hurdle model. Note that coefficients in the "zero hurdle model" section of the output relate predictors to the log-odds of being a non-zero (i.e., having at least one issue statement), which is opposite of the ZIP model.

a.  Visualize the distribution of the response variable totalIssuePages. Why might we consider using a hurdle model compared to a Poisson model? Why is a zero-inflated Poisson model not appropriate in this scenario?

    ```{r}

    issues <- read.csv("ambiguity.csv")

    ggplot(issues, aes(x = totalIssuePages)) +
      geom_histogram(fill = "lightblue", color = "black", alpha = 0.7) +
      labs(title = "Distribution of # of issues candidates commented on",
           x = "Number of Issues Commented On", y = "Frequency") +
      theme_minimal() +
      scale_x_continuous(breaks = seq(0, max(issues$totalIssuePages, na.rm = TRUE), by = 10))
    ```

    Given the excess of zeros, we should consider using a hurdle model rather than a Poisson model. A hurdle model is more appropriate in this context because we are interested in finding the variables that predict candidate silence (commenting on 0 issues). A hurdle model does this, relating predictors to the log-odds of being a non-zero (i.e., having at least one issue statement). A zero-inflated model would not be appropriate here since it would assume two distinct types of zeros: one type being candidates who always comment on 0 issues and the other type being candidates who, on this occasion, commented on 0 issues. We don't want to have these separate categories, since we are simply interested in the predictors of candidate silence for any reason.

b.  Create a plot of the empirical log odds of having at least one issue statement by ideology. You may want to group ideology values first. What can you conclude from this plot?

    ```{r}

    issues_new <- issues |>
      filter(!is.na(ideology))

    issues_new$ideologybin <- cut_interval(issues_new$ideology, n = 5)

    log_odds_data <- issues_new |>
      group_by(ideologybin) |>
      summarise(
        prob_one_issue = mean(totalIssuePages > 0, na.rm = TRUE),
        log_odds = log(prob_one_issue / (1 - prob_one_issue))
      )

    ggplot(log_odds_data, aes(x = ideologybin, y = log_odds)) +
      geom_bar(stat = "identity", fill = "lightblue", color = "black", alpha = 0.7) +
      labs(title = "Empirical Log-Odds of Having at Least One Issue Statement by Ideology",
           x = "Ideology Bin", y = "Log-Odds") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))

    ```

    From this plot, we can conclude that the empirical log odds of having at least one issue statement is higher among candidates with a ideological orientation that is more towards the right. There appears to be a steady increase in log odds as we move from left-leaning to right-leaning candidates.

c.  Create a hurdle model with ideology and democrat as predictors in both parts. Display the model. Interpret ideology in both parts of the model.

    ```{r, message = F, warning = F}

    library(pscl)

    hurdle_model <- hurdle(totalIssuePages ~ ideology + democrat, data = issues_new, dist = "poisson")

    coef(hurdle_model)|>
      tidy(digits = 4) |>
      kable()
    ```

    ```{r}

    exp(-0.005902)
    ```

    For every 1 point increase in the ideology scale, the average number of issues commented on is expected to be multiplied by approximately 0.994 while controlling for whether or not a candidate is a Democrat.

    For every 1 point increase in the ideology scale, the log odds of having at least one issue statement is expected to increase by 0.575 while controlling for whether or not a candidate is a Democrat.

d.  Repeat (d), but include an interaction in both parts. Interpret the interaction in the zero hurdle part of the model.

    ```{r, message = F, warning = F}

    hurdle_model_int <- hurdle(totalIssuePages ~ ideology + democrat + ideology * democrat, data = issues_new, dist = "poisson")

    coef(hurdle_model_int)|>
      tidy(digits = 4) |>
      kable()
    ```

    ```{r}

    (1.3667 - 1.3995)
    ```

    For Democrats candidates, for a 1 point increase in the ideology scale, we expect the log odds of having at least one issue statement to decrease by 0.0328 while controlling for the other variables in the model.

# Grading

| **Total**             | **39** |
|-----------------------|:------:|
| Ex 1                  |   4    |
| Ex 2                  |   6    |
| Ex 3                  |   8    |
| Ex 4                  |   8    |
| Ex 5                  |   10   |
| Workflow & formatting |   3    |

The "Workflow & formatting" grade is to based on the organization of the assignment write up along with the reproducible workflow. This includes having an organized write up with neat and readable headers, code, and narrative, including properly rendered mathematical notation. It also includes having a reproducible .Rmd document that can be rendered to reproduce the submitted PDF.

## References
